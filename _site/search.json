[
  {
    "objectID": "doc/sept.html",
    "href": "doc/sept.html",
    "title": "1 Executive Summary",
    "section": "",
    "text": "List of changes (if any) in the input data, including estimated catches assumed for the current year and projected catches for current year + 1 and current year + 2. List of changes (if any) in the assessment methodology. This is one of the most important sections of the SAFE report. Common mistakes in this section include: 1) listing something that has not changed, and 2) not listing something that has changed.\n\n\n\nThis presentation lacks any new data and mainly focusses on issues raised by the SSC and includes some model development changes. In particular, we enhanced the capability of the full-feedback loop by modifying the code to work as an operating model. We then linked this to a test comparing a management procedure that has some merit given a critique on the nature of the stock-recruitment relationship (SRR) conforming to the available data. We note that some new research has indicated that the value of \\(\\sigma_R\\) can be reasonably well estimated in bot traditional stock assessment models and in state-space versions. However, we caution against strict adherence to the estimates. This is because in the case for pollock, the SRR is heavily influenced by data to the right of \\(B_{MSY}\\) instead of nearer the origin (where measures of “steepness” might most reliably be estimated). The SRR is thus linked to the Tier 1 fishing mortality recommendation in two ways: 1) by the assumption about \\(\\sigma_R\\) (smaller values increase the “precision” of \\(F_{MSY}\\)) and 2) by having most of the data far from the origin and hence having steepness affected observations that are distant from the origin.\n\n\n\n\n\n\nThe SSC would prefer not to make a risk table adjustment based on the difference from Tier 1 to Tier 3 again during the 2024 assessment cycle. The SSC requests that the next stock assessment bring back a new approach that may include development of a constant buffer based on factors extrinsic to the stock assessment (ecosystem function), or a better representation of the uncertainty in the Tier 1 and control rule calculations such that a reduction from maximum ABC is not needed every year.\n\nWe approached this by first examining the stock recruitment relationship (SRR) and review the assumptions that the SSC has used to classify this stock in Tier 1 of the BSAI FMP. This is covered under a separate request by the SSC detailed below. We also attempted to consider factors that explicitly acknowledge the importance of pollock to the EBS ecosystem. We propose a management procedure that provides stability in the ABC advice each year and tracks historical adjustments as needed during periods of spawning biomass declines below target (where here we propose using a target geared towards 40+ years of experience managing this fishery).\n\nUse posterior distributions from the MCMC to determine probabilities in the risk table and expand the columns in the risk table to include the recommended ABC (and potentially higher values).\n\nWe interpret this request to refer to the decision table included in the assessment and not the risk-table that is standardly produced for all groundfish assessments. Using the posterior distributions to compute probabilities requires some simple code modifications. Since previous results indicated that asymptotic approximations performed similarly near the mode, we had used them as a shortcut method to make the decision table.\n\nIdentify where MLE estimates are being used and where MCMC estimates are being used. Also see the SSC’s General Stock Assessment Comments to include convergence diagnostics any time Bayesian results are reported. If MCMC diagnostics continue to appear adequate, reference points could be calculated using the posterior distribution used, rather than an analytical calculation.\n\nMLE and asymptotic approximations have always been used are used for advice. Results from sampling the posterior distribution have been used as a comparison and to show inter-relationships. Just requires some code modifications to do the computations off of the posteriors\n\nThe SSC recommends that consideration be given to removal of the Japanese fishery CPUE index (1965-76) from the assessment, because this data set no longer seems to contribute to the assessment. A sensitivity test should be done to evaluate the effects of data removal on the assessment.\n\nWe investigated this and report on it here. \n\nCatch-at-age data provided by foreign fishing agencies in the pre-Magnuson era were not produced using the same aging criteria as the AFSC age-and-growth program. Consideration should be given to removal of these data from the assessment. A sensitivity test should be done to evaluate the effects of data removal on the assessment.\n\nWe also investigated that in this report\n\nDocument the method used for determining the selectivity to use in the forward projections and continue to evaluate projection variability due to selectivity. The SSC appreciates the selectivity retrospective comparison and suggests that it might be helpful to limit the comparison to the projection used in each year against only the most recent (best) estimate of selectivity for that year.\n\nWe have been clear about projection assumptions used for selectivity and will provide an updated retrospective presentation for this year’s assessment. In this report, we evaluated the sensitivity of Tier 1 ABC given different selectivity estimtates from historical annual values. \n\nThe SSC supports the use of posterior predictive distributions, an underutilized tool in fisheries science, but common in other fields. To fully implement this approach to Bayesian model checking the SSC recommends plotting a histogram for each data source of the percentile of the predictive distribution in which each data point lies, noting that in a highly consistent model this histogram would be uniform.\n\nIn Bayesian statistics, evaluating the performance of a model using the percentile of the posterior predictive distribution is a common approach. This process involves comparing observed data to predictions made by the model and we understand the calculations that would be needed but have yet to implement the necessary code. We highlight the approach in a section discussing Bayesian diagnostics in this report.\n\nThere is an apparent shift towards older ages in fisheries and trawl survey selectivity that should be investigated further.\n\nThis is illustrated in the selectivity plots presented in last year’s report. Relative to historical estimates, the shift seems consistent with past years.\n\nThe SSC agrees with the BSAI GPT’s proposal in their presentation to move the multi-species model out of the pollock stock assessment, where it has been included as an appendix since it was first developed. Instead, they suggested it would be a separate chapter listed in parallel with the ESR, as it applies to multiple stocks and informs the ESRs.\n\nTechnically it’s presented as part of the BSAI assessment. Agree that it should be highlighted on its own. In this report we included the age and year specific estimates of natural mortality from CEATTLE.\n\nThe SSC suggests revisiting the treatment of the stock-recruit relationship in the assessment model using recent improvements in modeling approaches and a longer time series that encompasses the recent warm period in the EBS. Recruitment deviates should be from the stock-recruit relationship and should model variability among annual recruitment estimates based on information in the data and residual variability. The estimation process should ensure that log-normally distributed recruitments are mean unbiased, resulting in unbiased biomass estimates. If an informative prior is used for steepness, it should be based on a meta-analysis of related species and reflect the uncertainty of that meta-analysis. Further consideration of time periods (as in previous analyses) and the influence of temperature on the stock-recruit relationship may be helpful. The SSC recognizes that there were significant recent analyses in 2016, 2018 and 2020 and is not requesting a repeat of those but a review of previous work would be helpful.\n\nWe examine a model where the SRR applies over all age classes along with a reevaluation of a number of factors that affect the SRR and the \\(F_{MSY}\\) values. We include a few model results where temperature is in the condition of the SRR. We also note that an evaluation of different ‘regimes’ or periods of low or higher recruitment is presented as part of the standard assessment presention.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#summary-of-changes-in-assessment-inputs",
    "href": "doc/sept.html#summary-of-changes-in-assessment-inputs",
    "title": "1 Executive Summary",
    "section": "",
    "text": "List of changes (if any) in the input data, including estimated catches assumed for the current year and projected catches for current year + 1 and current year + 2. List of changes (if any) in the assessment methodology. This is one of the most important sections of the SAFE report. Common mistakes in this section include: 1) listing something that has not changed, and 2) not listing something that has changed.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#summary-of-results",
    "href": "doc/sept.html#summary-of-results",
    "title": "1 Executive Summary",
    "section": "",
    "text": "This presentation lacks any new data and mainly focusses on issues raised by the SSC and includes some model development changes. In particular, we enhanced the capability of the full-feedback loop by modifying the code to work as an operating model. We then linked this to a test comparing a management procedure that has some merit given a critique on the nature of the stock-recruitment relationship (SRR) conforming to the available data. We note that some new research has indicated that the value of \\(\\sigma_R\\) can be reasonably well estimated in bot traditional stock assessment models and in state-space versions. However, we caution against strict adherence to the estimates. This is because in the case for pollock, the SRR is heavily influenced by data to the right of \\(B_{MSY}\\) instead of nearer the origin (where measures of “steepness” might most reliably be estimated). The SRR is thus linked to the Tier 1 fishing mortality recommendation in two ways: 1) by the assumption about \\(\\sigma_R\\) (smaller values increase the “precision” of \\(F_{MSY}\\)) and 2) by having most of the data far from the origin and hence having steepness affected observations that are distant from the origin.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#responses-to-ssc-and-plan-team-comments",
    "href": "doc/sept.html#responses-to-ssc-and-plan-team-comments",
    "title": "1 Executive Summary",
    "section": "",
    "text": "The SSC would prefer not to make a risk table adjustment based on the difference from Tier 1 to Tier 3 again during the 2024 assessment cycle. The SSC requests that the next stock assessment bring back a new approach that may include development of a constant buffer based on factors extrinsic to the stock assessment (ecosystem function), or a better representation of the uncertainty in the Tier 1 and control rule calculations such that a reduction from maximum ABC is not needed every year.\n\nWe approached this by first examining the stock recruitment relationship (SRR) and review the assumptions that the SSC has used to classify this stock in Tier 1 of the BSAI FMP. This is covered under a separate request by the SSC detailed below. We also attempted to consider factors that explicitly acknowledge the importance of pollock to the EBS ecosystem. We propose a management procedure that provides stability in the ABC advice each year and tracks historical adjustments as needed during periods of spawning biomass declines below target (where here we propose using a target geared towards 40+ years of experience managing this fishery).\n\nUse posterior distributions from the MCMC to determine probabilities in the risk table and expand the columns in the risk table to include the recommended ABC (and potentially higher values).\n\nWe interpret this request to refer to the decision table included in the assessment and not the risk-table that is standardly produced for all groundfish assessments. Using the posterior distributions to compute probabilities requires some simple code modifications. Since previous results indicated that asymptotic approximations performed similarly near the mode, we had used them as a shortcut method to make the decision table.\n\nIdentify where MLE estimates are being used and where MCMC estimates are being used. Also see the SSC’s General Stock Assessment Comments to include convergence diagnostics any time Bayesian results are reported. If MCMC diagnostics continue to appear adequate, reference points could be calculated using the posterior distribution used, rather than an analytical calculation.\n\nMLE and asymptotic approximations have always been used are used for advice. Results from sampling the posterior distribution have been used as a comparison and to show inter-relationships. Just requires some code modifications to do the computations off of the posteriors\n\nThe SSC recommends that consideration be given to removal of the Japanese fishery CPUE index (1965-76) from the assessment, because this data set no longer seems to contribute to the assessment. A sensitivity test should be done to evaluate the effects of data removal on the assessment.\n\nWe investigated this and report on it here. \n\nCatch-at-age data provided by foreign fishing agencies in the pre-Magnuson era were not produced using the same aging criteria as the AFSC age-and-growth program. Consideration should be given to removal of these data from the assessment. A sensitivity test should be done to evaluate the effects of data removal on the assessment.\n\nWe also investigated that in this report\n\nDocument the method used for determining the selectivity to use in the forward projections and continue to evaluate projection variability due to selectivity. The SSC appreciates the selectivity retrospective comparison and suggests that it might be helpful to limit the comparison to the projection used in each year against only the most recent (best) estimate of selectivity for that year.\n\nWe have been clear about projection assumptions used for selectivity and will provide an updated retrospective presentation for this year’s assessment. In this report, we evaluated the sensitivity of Tier 1 ABC given different selectivity estimtates from historical annual values. \n\nThe SSC supports the use of posterior predictive distributions, an underutilized tool in fisheries science, but common in other fields. To fully implement this approach to Bayesian model checking the SSC recommends plotting a histogram for each data source of the percentile of the predictive distribution in which each data point lies, noting that in a highly consistent model this histogram would be uniform.\n\nIn Bayesian statistics, evaluating the performance of a model using the percentile of the posterior predictive distribution is a common approach. This process involves comparing observed data to predictions made by the model and we understand the calculations that would be needed but have yet to implement the necessary code. We highlight the approach in a section discussing Bayesian diagnostics in this report.\n\nThere is an apparent shift towards older ages in fisheries and trawl survey selectivity that should be investigated further.\n\nThis is illustrated in the selectivity plots presented in last year’s report. Relative to historical estimates, the shift seems consistent with past years.\n\nThe SSC agrees with the BSAI GPT’s proposal in their presentation to move the multi-species model out of the pollock stock assessment, where it has been included as an appendix since it was first developed. Instead, they suggested it would be a separate chapter listed in parallel with the ESR, as it applies to multiple stocks and informs the ESRs.\n\nTechnically it’s presented as part of the BSAI assessment. Agree that it should be highlighted on its own. In this report we included the age and year specific estimates of natural mortality from CEATTLE.\n\nThe SSC suggests revisiting the treatment of the stock-recruit relationship in the assessment model using recent improvements in modeling approaches and a longer time series that encompasses the recent warm period in the EBS. Recruitment deviates should be from the stock-recruit relationship and should model variability among annual recruitment estimates based on information in the data and residual variability. The estimation process should ensure that log-normally distributed recruitments are mean unbiased, resulting in unbiased biomass estimates. If an informative prior is used for steepness, it should be based on a meta-analysis of related species and reflect the uncertainty of that meta-analysis. Further consideration of time periods (as in previous analyses) and the influence of temperature on the stock-recruit relationship may be helpful. The SSC recognizes that there were significant recent analyses in 2016, 2018 and 2020 and is not requesting a repeat of those but a review of previous work would be helpful.\n\nWe examine a model where the SRR applies over all age classes along with a reevaluation of a number of factors that affect the SRR and the \\(F_{MSY}\\) values. We include a few model results where temperature is in the condition of the SRR. We also note that an evaluation of different ‘regimes’ or periods of low or higher recruitment is presented as part of the standard assessment presention.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#evaluating-the-impact-of-selectivity-assumptions",
    "href": "doc/sept.html#evaluating-the-impact-of-selectivity-assumptions",
    "title": "1 Executive Summary",
    "section": "2.1 Evaluating the impact of selectivity assumptions",
    "text": "2.1 Evaluating the impact of selectivity assumptions\non stock recruitment relationships (SRR)\nTo examine the assumptions about fishery selectivity variability we ran alternative model configurations where selectivity variability was contrasted. In one configuration it was constrained such that the fishing mortality was considered completely separable with respect to age and one where there was limited constraint on the selectivity. This later model is similar in nature to traditional VPA models where the catch at age is assumed known precisely. The resulting selectivity patterns are shown in Figure 1. Results showed that very little difference between a freely specified selectivity model (Figure 2) Results comparing the constrained selectivity differed substantially from last year’s configuration (Figure 3).\nThe large differences due to assuming separability also impacts the estimates of the stock recruitment relationship (Figure 4). This figure also dipicts the different magnitude of the recent recruitment and an increased uncertainty. In particular, the 2018 year class is estimated to be much larger in the separable model.\nAnother form of evaluating the selectivity estimates was to simply apply each of the annual selectivity estimates (or partial Fs) from the past 20 years. We note that the base result used the mean selectivity over the recent 2 years; specifically, the mean selectivity for 2021 and 2022 for the 2023 terminal year assessment.\nResults show that …xxx\n\n\n\n\n\n\n\n\nFigure 1: Selectivity-at-age patterns for three models: last-year’s, separable, and VPA.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Model results comparing last year’s selected model with one where the selectivity is more highly variable over time (VPA). Recruitment is shown in the top panel and spawning biomass in the lower.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Model results comparing last year’s selected model with one where the selectivity is constant over time (separable). Recruitment is shown in the top panel and spawning biomass in the lower.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Model results comparing last year’s selected model with one where the selectivity is fixed over time (separable) for the estimated stock-recruitment relationship. Note that the vertical bars represent the 95% confidence intervals for the age-1 recruitment.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#time-series-length-for-the-stock-recruitment-relationship-conditioning",
    "href": "doc/sept.html#time-series-length-for-the-stock-recruitment-relationship-conditioning",
    "title": "1 Executive Summary",
    "section": "2.2 Time series length for the stock-recruitment relationship conditioning",
    "text": "2.2 Time series length for the stock-recruitment relationship conditioning\nThe SSC requested that the full time series be included for the SRR conditioning. Extending the time series back to 1964 resulted in a different shaped curve with higher steepness (Figure 5). This was due to the inclusion of age-1 recruits from the early years. The inclusion of sea-surface temperature as a covariate to the full time series moderated this increase slightly (Figure 7).\n\n\n\n\n\n\n\n\nFigure 5: Model results comparing last year’s selected model (SRR 1978-2021) with one where the the full time series is used for the stock-recruitment relationship conditioning. The vertical bars represent the 95% confidence intervals for the age-1 recruitment.\n\n\n\n\n\nAs another consideration for Tier 1 and Tier 3, we recognized that the SPR rate for the 2023 assessment that corresponded to a value of about \\(F_{32\\%}\\). For contrast we used a similar SRR curve condition approach asking the question “what SRR satisfies the constraint that out \\(F_{35\\%}\\) = \\(F_{MSY}\\).”\n\n\n\n\n\n\n\n\nFigure 6: Model results comparing last year’s selected model (SRR 1978-2021) with one where the SRR was conditioned such that \\(F_{MSY}\\) was equal the the SPR rate of \\(F_{35}\\). The vertical bars represent the 95% confidence intervals for the age-1 recruitment.\n\n\n\n\n\nAn alternative SRR conditioning exercise was conducted where the year range for the conditioning of the curve was dropped in successive years. This was intended to show how sensitive the curve is to the years included in the analysis. We expect that it should revert to the prior as fewer years are included in the conditioning of the SRR curve.\nNon-stationarity XXX xxx",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#including-temperature-effects-in-the-stock-recruitment-relationship",
    "href": "doc/sept.html#including-temperature-effects-in-the-stock-recruitment-relationship",
    "title": "1 Executive Summary",
    "section": "2.3 Including temperature effects in the stock-recruitment relationship",
    "text": "2.3 Including temperature effects in the stock-recruitment relationship\n\n\n\n\n\n\n\n\nFigure 7: Model results comparing the model (SRR 1964-2021) with one including sea-surface tempurature a covariate. The vertical bars represent the 95% confidence intervals for the age-1 recruitment.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#removing-the-impact-of-the-prior-on-the-stock-recruitment-relationship",
    "href": "doc/sept.html#removing-the-impact-of-the-prior-on-the-stock-recruitment-relationship",
    "title": "1 Executive Summary",
    "section": "2.4 Removing the impact of the prior on the stock-recruitment relationship",
    "text": "2.4 Removing the impact of the prior on the stock-recruitment relationship\n\n\n\n\n\n\n\n\nFigure 8: Model results comparing last year’s model (SRR 1978-2021) with ones excluding the effect of prior distributions and different period lengths. The vertical bars represent the 95% confidence intervals for the age-1 recruitment.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#beverton-holt-versus-ricker-stock-recruitment-relationship",
    "href": "doc/sept.html#beverton-holt-versus-ricker-stock-recruitment-relationship",
    "title": "1 Executive Summary",
    "section": "2.5 Beverton-Holt versus Ricker stock-recruitment relationship",
    "text": "2.5 Beverton-Holt versus Ricker stock-recruitment relationship\n\n\n\n\n\n\n\n\nFigure 9: Model results comparing the Ricker model (SRR 1978-2021) with one assuming Beverton-Holt (short and long periods). The vertical bars represent the 95% confidence intervals for the age-1 recruitment.\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Model results comparing the Ricker model (SRR 1978-2021) with one assuming Beverton-Holt (short and long periods). The vertical bars represent the 95% confidence intervals for the age-1 recruitment.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#specified-variability-about-the-srr",
    "href": "doc/sept.html#specified-variability-about-the-srr",
    "title": "1 Executive Summary",
    "section": "2.6 Specified variability about the SRR",
    "text": "2.6 Specified variability about the SRR\nThe SSC requested that we ensure that the bias correction is applied in the application of fitting the SRR. We confirm that in past assessments, for the period which the SRR curve was applied, the bias correction term was included. Specifically,\n\\[ \\hat{R}_t = f(B_{t-1}) e^{\\epsilon_t-0.5 \\sigma_R^2} \\]\nwhere \\(\\epsilon_t \\sim N(0, \\sigma_R^2)\\). Here the production function (which generates age-1 recruitment) is a function of spawning biomass in the previous year (\\(f(B_{t-1})\\)). Since this function “generates” age-1 recruitment from a lognormal distribution, the basis for this must be scaled accordingly. Therefore the assessment model numbers-at-age one (\\(\\dot{R_t}=N_{1,t}\\)), must account for the bias based on the SRR. This leads to the recruitment component of the negative log-likelihood as\n\\[ -ln(L_{rec}) = \\sum_{t=1}^{T} \\left[\\frac{\\left(\\chi_t + \\frac{\\sigma^2_R}{2}\\right)^2}{2\\sigma^2_R} + ln(\\sigma_R) \\right] \\]\nwhere \\(\\chi_t = \\log(\\dot{R}_t) - \\log(\\hat{R}_t)\\). Note that the bias correction term falls within the likelihood because the bias is a function of the model estimates.\nFor this case we evaluated the impact of the \\(\\sigma_R\\) prior on the ABC estimates. xxx\n\n\n\n\n\n\n\n\nFigure 11: SRR curves as estimated in the 2023 assessment (top) and conditioned on an alternative Fmsy assumptions (middle and bottom).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: Impact of \\(\\sigma_R\\) on the ABC value from the 2023 assessment.\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Impact of \\(\\sigma_R\\) on the ABC value from the 2023 assessment.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: SRR curves as estimated in the 2023 assessment for different fixed values of sigmaR.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15: SRR curves as estimated in the 2023 assessment for different terminal years included in the estimation.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: SRR curves as estimated in the 2023 assessment for different terminal years included in the estimation (animated).",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#sensitivity-of-the-selectivity-estimate-on-the-srr",
    "href": "doc/sept.html#sensitivity-of-the-selectivity-estimate-on-the-srr",
    "title": "1 Executive Summary",
    "section": "2.7 Sensitivity of the selectivity estimate on the SRR",
    "text": "2.7 Sensitivity of the selectivity estimate on the SRR\nFor this set of experiments, we evaluated the SRR curve given the past 20 years of selectivity estimates. From this we get a set of SRR curves that are conditioned on the selectivity estimate AND the MSY value. The script to run this set involved reading in the control file and modifying the option for which years to include for the selectivity estimate (can be specific years or a range of years from which to use).\nInitial results showed that while the SRR curve was insensitive to the selectivity estimate (Figure 17), there could be large and variable impacts on the ABC estimates (Figure 18). This was due to the fact that the selectivity changes can shift to younger or older ages in some years. This also\n\n\n\n\n\n\n\n\nFigure 17: SRR curves as estimated in the 2023 assessment (top) and conditioned on an alternative Fmsy assumptions (middle and bottom).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 18: Difference in projected Tier 1 ABC by year of selectivity estimate from the 2023 assessment.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#simulation-testing-the-stock-recruitment-estimation",
    "href": "doc/sept.html#simulation-testing-the-stock-recruitment-estimation",
    "title": "1 Executive Summary",
    "section": "2.8 Simulation testing the stock recruitment estimation",
    "text": "2.8 Simulation testing the stock recruitment estimation\nA simple simulation framework was set up to show how patterns of the Ricker SRR can be influenced by the available “points” used in the estimation. We start with the estimates of spawning biomass and recruits from the 2023 accepted model. As in the assessment, we selected the period from 1978-2022 and fit a Ricker SRR. We then replicated the estimation using random error about both the estimate of recruitment and spawning biomass. These “data” were then sampled with replacement. The\n100 sets of data and resulting curves showed that the slope at the origin tends to be higher for these cases (are shown in (Figure 19). Note that these curves differ from the actual assessment since the fitting is done separately (we used the linear regression log recruits-per-spawning biomass vs spawning biomass). The point of this exercise is to show that extrapolating the fitted curves outside of the range of data (i.e., at smaller spawning stock sizes) can lead to very different and positively biased productivity estimates. The slope at the origin is a key parameter in the Ricker SRR and governs productivity estimates and consequently, \\(F_{MSY}\\) estimates. This suggests that applying the SRR estimates for management purposes (in Tier 1) may be inappropriate given this apparent potential for bias.\n\n\n\n\n\n\n\n\nFigure 19: Results from simulation-estimation scenarios from the type of data available for EBS pollock, 1978-2022",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  },
  {
    "objectID": "doc/sept.html#steps-for-judging-model-performance-based-on-the-posterior-predictive-distributions",
    "href": "doc/sept.html#steps-for-judging-model-performance-based-on-the-posterior-predictive-distributions",
    "title": "1 Executive Summary",
    "section": "7.1 Steps for judging model performance based on the posterior predictive distributions",
    "text": "7.1 Steps for judging model performance based on the posterior predictive distributions\nAfter obtaining posterior samples, let’s denote these samples as \\(\\theta_1\\), \\(\\theta_2\\), \\(\\ldots\\), \\(\\theta_N\\), where N is the number of posterior samples. Next is to generate predictive samples. For each posterior sample \\(\\theta_i\\), generate a predictive sample \\(y_i^{\\text{pred}}\\) from the likelihood function \\(p(y \\mid \\theta_i)\\). These predictive samples form the posterior predictive distribution. This step is repeated for each posterior sample, resulting in a collection of predicted values.\nTo judge model performance, compare the observed data \\(y_{\\text{obs}}\\) with the posterior predictive distribution. A common approach is to use the percentile (or quantile) of the observed data in the posterior predictive distribution.\nFor each observed data point \\(y_{\\text{obs}}\\), calculate its percentile in the corresponding posterior predictive distribution. This is done by determining the proportion of predictive samples that are less than or equal to the observed value.\nGiven M predictive samples \\(y_1^{\\text{pred}}\\), \\(y_2^{\\text{pred}}\\), \\(\\ldots\\), \\(y_M^{\\text{pred}}\\). The percentile p of the observed value \\(y_{\\text{obs}}\\) can be computed as:\n\\(p = \\frac{\\sum_{j=1}^M \\mathbb{I}(y_j^{\\text{pred}} \\leq y_{\\text{obs}})}{M}\\)\nHere, \\(\\mathbb{I}(\\cdot)\\) is an indicator function that returns 1 if the condition inside is true, and 0 otherwise. This gives the count the predictive samples are less than or equal to the observed value divided by the total number of samples.\nUnder a well-calibrated model, the observed data should fall uniformly across the range of the posterior predictive distribution. This implies that the percentiles should be roughly uniformly distributed between 0 and 1. A histogram of these percentiles can be evaluated relative to a uniform distribution. Significant deviations from uniformity may indicate model misspecification.\nPosterior predictive checks can also be facilitated by visualizing the posterior predictive distribution. This can includes comparing the observed data’s summary statistics (e.g., mean, variance) relative to those of the posterior predictive distribution.",
    "crumbs": [
      "EBS pollock assessment, September 2024"
    ]
  }
]